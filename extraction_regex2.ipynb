{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.layout import LAParams\n",
    "import re\n",
    "import os\n",
    "\n",
    "def Approved_Subjects(student_extract_pdf):\n",
    "    '''Return approved subject keys from the academic extract'''\n",
    "    #Ideal layout parameters:\n",
    "    laparams = LAParams(line_overlap=0.5,\n",
    "        char_margin=95.0, line_margin=2, word_margin=0.5,\n",
    "        boxes_flow=0.5, detect_vertical=False, all_texts=False)\n",
    "    #Reading pdf to string\n",
    "    extract = extract_text(student_extract_pdf,laparams=laparams)\n",
    "\n",
    "    #Filter from \"extrato\" all the lines begining with a subject key\n",
    "    attended_subjects = re.findall(r\"[A-Z]{3}\\d{5}.*\",extract) #print(attended_subjects)\n",
    "    #Filter the approved subjects and the subjects exempt through the special pandemic period (AAREs) \n",
    "    approved_subjects = [att_sub.split(\" \",1)[0] for att_sub in attended_subjects if (\"APR\" in att_sub or len(att_sub) == 12)]\n",
    "    return approved_subjects \n",
    "\n",
    "#Approved_Subjects(\"extrato_escolar.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the prerequisite dictionary! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Subject_Dict(matriz_pdf):\n",
    "    '''Build the subject database, with the subject key, name and prerequitites'''\n",
    "    laparams = LAParams(line_overlap=0.5,\n",
    "    char_margin=500, line_margin=2, word_margin=0.5,\n",
    "    boxes_flow=0.5, detect_vertical=False, all_texts=False)\n",
    "    text = extract_text(matriz_pdf,laparams=laparams)\n",
    "\n",
    "    #This first expression fixes the side effect of the pdf reader putting prerequisites in new lines\n",
    "    #substitute the newline for a comma just between prerequisites\n",
    "    exp = r\",\\n[A-Z]{3}\\d{5}\"\n",
    "    def repl(m):\n",
    "        #print(m.group(0)[2:])\n",
    "        return(\",\"+m.group(0)[2:])\n",
    "\n",
    "    fixed_prerequisites=re.sub(exp,repl,text)\n",
    "    \n",
    "    exp2 = r\"[A-Z]{3}\\d{5}.*[A-Z]{3}\\d{5}\"\n",
    "    subjects_prerequisites = re.findall(exp2,fixed_prerequisites,re.M) \n",
    "    subjects_prerequisites\n",
    "\n",
    "    #~improove this repetition of .split()~\n",
    "    #prerequisites = {x.split()[0]:x.split()[-1] for x in subjects_prerequisites}\n",
    "    prerequisites = {x[0]:x[-1].split(\",\") for x in [y.split() for y in subjects_prerequisites]}\n",
    "    subject_names = {x[0]:x[-2] for x in [y.split() for y in subjects_prerequisites]}\n",
    "\n",
    "    return prerequisites,subject_names\n",
    "#Prerequisite_Dict(\"2014-MatrizCurricularComputacao.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Subjects_Demand(prerequisites,approved_subjects):\n",
    "    '''Finds the subjects the student have the possibility to attend, by not being approved and having the prerequisites'''\n",
    "    def Is_sublist(sublist,list):\n",
    "        return set(sublist) <= set(list)\n",
    "\n",
    "    subjects_demand = [subject for subject in prerequisites.keys() if \n",
    "    (subject not in approved_subjects and Is_sublist(prerequisites[subject],approved_subjects))] \n",
    "    return subjects_demand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF01113 ParadigmasdeLinguagensdeProgramação\n",
      "MAT01201 EstatísticaEProbabilidades\n",
      "INF01202 EstruturadeDadosII\n",
      "INF01204 SistemaOperacional\n",
      "INF01203 ProgramaçãoOrientadaaObjetos\n",
      "INF01201 AnáliseeProjetodeSistemas\n",
      "INF01206 BancodeDadosII\n",
      "INF01211 PesquisaOperacional\n"
     ]
    }
   ],
   "source": [
    "#Complete for one student\n",
    "prerequisites,subject_names = Subject_Dict(\"2014-MatrizCurricularComputacao.pdf\")\n",
    "approved_subjects = Approved_Subjects(\"extrato_escolar.pdf\")\n",
    "subjects_demand = Subjects_Demand(prerequisites,approved_subjects)\n",
    "\n",
    "for subject_key in subjects_demand:\n",
    "    print(subject_key, subject_names[subject_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Putting it all toghether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Aggregate_Demand(extratos,prerequisites):\n",
    "    for extrato in extratos:\n",
    "        approved_subjects = Approved_Subjects(extrato)\n",
    "        subjects_demand = Subjects_Demand(prerequisites,approved_subjects)\n",
    "        for subject in subjects_demand:\n",
    "            if subject not in aggregate_demand:\n",
    "                aggregate_demand[subject] = 1 \n",
    "            else:\n",
    "                aggregate_demand[subject] += 1\n",
    "    return aggregate_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ext_-_JVFD.pdf', 'extrato_escolar.pdf', 'extrato_ze.pdf']"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Read_Files_in_Folder():\n",
    "    files = os.listdir()\n",
    "    return files\n",
    "\n",
    "def Extratos(files):     \n",
    "    extratos = [file for file in files if file[-3:] == \"pdf\" and \"Matriz\" not in file]\n",
    "    #extratos = [\"extrato_escolar.pdf\",\"Ext_-_JVFD.pdf\",\"extrato_ze.pdf\"]\n",
    "    return extratos \n",
    "files = Read_Files_in_Folder()\n",
    "Extratos(files)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 INF01113 ParadigmasdeLinguagensdeProgramação\n",
      "3 MAT01201 EstatísticaEProbabilidades\n",
      "3 INF01202 EstruturadeDadosII\n",
      "3 INF01204 SistemaOperacional\n",
      "3 INF01203 ProgramaçãoOrientadaaObjetos\n",
      "3 INF01201 AnáliseeProjetodeSistemas\n",
      "3 INF01206 BancodeDadosII\n",
      "3 INF01211 PesquisaOperacional\n",
      "1 FIS01103 FísicaGeralII\n"
     ]
    }
   ],
   "source": [
    "extratos = Extratos(files)\n",
    "\n",
    "prerequisites,subject_names = Subject_Dict(\"2014-MatrizCurricularComputacao.pdf\")\n",
    "aggregate_demand = {}\n",
    "aggregate_demand = Aggregate_Demand(extratos,prerequisites)\n",
    "\n",
    "for subject_key in aggregate_demand.keys():\n",
    "    print(aggregate_demand[subject_key],subject_key,subject_names[subject_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studied the possibility of pickle for permanence, but json  seems more adequate for the project due to the human readable, small size of content and security in reading.\n",
    "import pickle\n",
    "dictionary_data = {\"a\": 1, \"b\": 2}\n",
    "\n",
    "a_file = open(\"data.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(dictionary_data, a_file)\n",
    "\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"data.pkl\", \"rb\")\n",
    "\n",
    "output = pickle.load(a_file)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##json workflow developing \n",
    "def Save_Dict_to_JSON(dict,json_file):\n",
    "    with open(json_file,'w') as f:\n",
    "        json.dump(dict,f)\n",
    "\n",
    "def Read_JSON_to_Dict(json_file):\n",
    "    with open(json_file,'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "Save_Dict_to_JSON(dictionary_data,\"test.json\")\n",
    "Read_JSON_to_Dict(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:think about the best approach to automatically check it there exists the names and prerequisites files\n",
    "# If they don't exist, build them.\n",
    "# TODO: Build the files with the fixes\n",
    "# TODO: Stablish a simple, also salves as json file to store the subject keys equivalences \n",
    "# TODO: profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'subjects_dict.json' sucssesfully loaded.\n",
      "1 Extracts processed.\n",
      "2 Extracts processed.\n",
      "3 Extracts processed.\n",
      "Aggregate Demand sucssesfully calculated.\n",
      "Results preview:\n",
      "['Sigla', 'Diciplina', 'Demanda']\n",
      "['INF01113', 'ParadigmasdeLinguagensdeProgramação', 3]\n",
      "['MAT01201', 'EstatísticaEProbabilidades', 3]\n",
      "['INF01202', 'EstruturadeDadosII', 3]\n",
      "['INF01204', 'SistemaOperacional', 3]\n",
      "['INF01203', 'ProgramaçãoOrientadaaObjetos', 3]\n",
      "['INF01201', 'AnáliseeProjetodeSistemas', 3]\n",
      "['INF01206', 'BancodeDadosII', 3]\n",
      "['INF01211', 'PesquisaOperacional', 3]\n",
      "['FIS01103', 'FísicaGeralII', 1]\n",
      "'RESULTS_aggregate_demand.csv' sucessfuly written!\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.layout import LAParams\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "def Read_Files_in_Folder():\n",
    "    files = os.listdir()\n",
    "    return files\n",
    "\n",
    "def Read_JSON_to_Dict(json_file):\n",
    "    try:\n",
    "        with open(json_file,'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return -1  \n",
    "\n",
    "def Save_Dict_to_JSON(dict,json_file):\n",
    "    with open(json_file,'w') as f:\n",
    "        json.dump(dict,f)\n",
    "\n",
    "def Save_CSV(table,csv_file_name):\n",
    "    with open(csv_file_name,'w') as csvfile:\n",
    "        writer = csv.writer(csvfile) \n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "    print(\"'\"+csv_file_name+\"'\",\"sucessfuly written!\")\n",
    "\n",
    "def Subject_Dict_prerequisites_names(files):\n",
    "    '''Return a subjects_dict with the subject keys, names and prerequisites'''\n",
    "    def _Build_prerequisites_names_Dict(matriz_pdf):\n",
    "        '''Build the subject database, with the subject key, name and prerequitites'''\n",
    "        laparams = LAParams(line_overlap=0.5,\n",
    "        char_margin=500, line_margin=2, word_margin=0.5,\n",
    "        boxes_flow=0.5, detect_vertical=False, all_texts=False)\n",
    "        text = extract_text(matriz_pdf,laparams=laparams)\n",
    "\n",
    "        #This first expression fixes the side effect of the pdf reader putting prerequisites in new lines\n",
    "        #substitute the newline for a comma just between prerequisites\n",
    "        exp = r\",\\n[A-Z]{3}\\d{5}\"\n",
    "        def repl(m):\n",
    "            #print(m.group(0)[2:])\n",
    "            return(\",\"+m.group(0)[2:])\n",
    "\n",
    "        fixed_prerequisites=re.sub(exp,repl,text)\n",
    "        \n",
    "        exp2 = r\"[A-Z]{3}\\d{5}.*[A-Z]{3}\\d{5}\"\n",
    "        subjects_prerequisites = re.findall(exp2,fixed_prerequisites,re.M) \n",
    "        subjects_prerequisites\n",
    "\n",
    "        #~improove this repetition of .split()~\n",
    "        #prerequisites = {x.split()[0]:x.split()[-1] for x in subjects_prerequisites}\n",
    "        prerequisites = {x[0]:x[-1].split(\",\") for x in [y.split() for y in subjects_prerequisites]}\n",
    "        subject_names = {x[0]:x[-2] for x in [y.split() for y in subjects_prerequisites]}\n",
    "        subject_dict = {\"names\":subject_names,\"prerequisites\":prerequisites}\n",
    "\n",
    "        Save_Dict_to_JSON(subject_dict,\"subjects_dict.json\")\n",
    "        print(\"'subjects_dict.json' sucssesfully built and loaded.\")\n",
    "        return subject_dict \n",
    "\n",
    "    dict = Read_JSON_to_Dict(\"subjects_dict.json\")\n",
    "    if dict == -1:\n",
    "        matriz_pdf = [pdf for pdf in files if \"Matriz\" in pdf][0]\n",
    "        if matriz_pdf == []:\n",
    "            #return \"Error! Neither 'subjects_dict.json' nor MatrizCurricular were not found.\"\n",
    "            return -1\n",
    "        else:\n",
    "            print(\"'subjects_dict.json' not found. Lets build it!\")\n",
    "            return _Build_prerequisites_names_Dict(matriz_pdf)\n",
    "    else:\n",
    "        print(\"'subjects_dict.json' sucssesfully loaded.\")\n",
    "        return dict \n",
    "\n",
    "def Extratos(files):     \n",
    "    files = os.listdir()\n",
    "    pdfs = [file for file in files if file[-3:] == \"pdf\"]\n",
    "    #extratos = [\"extrato_escolar.pdf\",\"Ext_-_JVFD.pdf\",\"extrato_ze.pdf\"]\n",
    "    extratos = [pdf for pdf in pdfs if \"Matriz\" not in pdf]\n",
    "    return extratos \n",
    "\n",
    "def Aggregate_Demand(extratos,prerequisites):\n",
    "    def _Approved_Subjects(student_extract_pdf):\n",
    "        '''Return approved subject keys from the academic extract'''\n",
    "        #Ideal layout parameters:\n",
    "        laparams = LAParams(line_overlap=0.5,\n",
    "            char_margin=95.0, line_margin=2, word_margin=0.5,\n",
    "            boxes_flow=0.5, detect_vertical=False, all_texts=False)\n",
    "        #Reading pdf to string\n",
    "        extract = extract_text(student_extract_pdf,laparams=laparams)\n",
    "\n",
    "        #Filter from \"extrato\" all the lines begining with a subject key\n",
    "        attended_subjects = re.findall(r\"[A-Z]{3}\\d{5}.*\",extract) #print(attended_subjects)\n",
    "        #Filter the approved subjects and the subjects exempt through the special pandemic period (AAREs) \n",
    "        approved_subjects = [att_sub.split(\" \",1)[0] for att_sub in attended_subjects if (\"APR\" in att_sub or len(att_sub) == 12)]\n",
    "        return approved_subjects \n",
    "\n",
    "    def _Subjects_Demand(prerequisites,approved_subjects):\n",
    "        '''Finds the subjects the student have the possibility to attend.\n",
    "        That is, unnatended subjects that the student already has the prerequisites'''\n",
    "        def Is_sublist(sublist,list):\n",
    "            return set(sublist) <= set(list)\n",
    "\n",
    "        subjects_demand = [subject for subject in prerequisites.keys() if \n",
    "        (subject not in approved_subjects and Is_sublist(prerequisites[subject],approved_subjects))] \n",
    "        return subjects_demand\n",
    "\n",
    "    aggregate_demand = {}\n",
    "    i = 0 \n",
    "    for extrato in extratos:\n",
    "        approved_subjects = _Approved_Subjects(extrato)\n",
    "        subjects_demand = _Subjects_Demand(prerequisites,approved_subjects)\n",
    "        for subject in subjects_demand:\n",
    "            if subject not in aggregate_demand:\n",
    "                aggregate_demand[subject] = 1 \n",
    "            else:\n",
    "                aggregate_demand[subject] += 1\n",
    "        print(i+1,\"Extracts processed.\")\n",
    "        i+=1\n",
    "    print(\"Aggregate Demand sucssesfully calculated.\\nResults preview:\")\n",
    "    return aggregate_demand\n",
    "\n",
    "def Final_Demand(aggregate_demand,subject_dict):\n",
    "    final_demand = [[\"Sigla\",\"Diciplina\",\"Demanda\"]]\n",
    "    print(final_demand[-1])\n",
    "    for subject,demand in aggregate_demand.items():\n",
    "        final_demand.append([subject,subject_dict[\"names\"][subject],demand])\n",
    "        print(final_demand[-1])\n",
    "    \n",
    "        \n",
    "    Save_CSV(final_demand,\"RESULTS_aggregate_demand.csv\")\n",
    "\n",
    "def main():\n",
    "    files = Read_Files_in_Folder()\n",
    "    subject_dict = Subject_Dict_prerequisites_names(files)\n",
    "    if subject_dict == -1:\n",
    "        return \"Error! Neither 'subjects_dict.json' nor MatrizCurricular were found in the current folder:\\n\"+os.getcwd()\n",
    "    else:\n",
    "        extratos = Extratos(files)\n",
    "        aggregate_demand = Aggregate_Demand(extratos,subject_dict[\"prerequisites\"])\n",
    "        Final_Demand(aggregate_demand,subject_dict)\n",
    "main()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##json workflow developing \n",
    "def Save_Dict_to_JSON(dict,json_file):\n",
    "    with open(json_file,'w') as f:\n",
    "        json.dump(dict,f)\n",
    "\n",
    "def Read_JSON_to_Dict(json_file):\n",
    "    try:\n",
    "        with open(json_file,'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return -1  \n",
    "\n",
    "\n",
    "Save_Dict_to_JSON(dictionary_data,\"test.json\")\n",
    "Read_JSON_to_Dict(\"test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def Save_CSV(table,csv_file_name):\n",
    "    with open(csv_file_name,'w') as csvfile:\n",
    "        writer = csv.writer(csvfile) \n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "    print(csv_file_name,\"sucessfuly written!\")\n",
    "\n",
    "final_demand = [['Sigla', 'Diciplina', 'Demanda'], ['INF01113', 'ParadigmasdeLinguagensdeProgramação', 3], ['MAT01201', 'EstatísticaEProbabilidades', 3], ['INF01202', 'EstruturadeDadosII', 3], ['INF01204', 'SistemaOperacional', 3], ['INF01203', 'ProgramaçãoOrientadaaObjetos', 3], ['INF01201', 'AnáliseeProjetodeSistemas', 3], ['INF01206', 'BancodeDadosII', 3], ['INF01211', 'PesquisaOperacional', 3], ['FIS01103', 'FísicaGeralII', 1]]\n",
    "Save_CSV(final_demand,\"teste.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
