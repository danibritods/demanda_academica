{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.layout import LAParams\n",
    "import re\n",
    "import os\n",
    "\n",
    "def Approved_Subjects(student_extract_pdf):\n",
    "    '''Return approved subject keys from the academic extract'''\n",
    "    #Ideal layout parameters:\n",
    "    laparams = LAParams(line_overlap=0.5,\n",
    "        char_margin=95.0, line_margin=2, word_margin=0.5,\n",
    "        boxes_flow=0.5, detect_vertical=False, all_texts=False)\n",
    "    #Reading pdf to string\n",
    "    extract = extract_text(student_extract_pdf,laparams=laparams)\n",
    "\n",
    "    #Filter from \"extrato\" all the lines begining with a subject key\n",
    "    attended_subjects = re.findall(r\"[A-Z]{3}\\d{5}.*\",extract) #print(attended_subjects)\n",
    "    #Filter the approved subjects and the subjects exempt through the special pandemic period (AAREs) \n",
    "    approved_subjects = [att_sub.split(\" \",1)[0] for att_sub in attended_subjects if (\"APR\" in att_sub or len(att_sub) == 12)]\n",
    "    return approved_subjects \n",
    "\n",
    "#Approved_Subjects(\"extrato_escolar.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the prerequisite dictionary! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Subject_Dict(matriz_pdf):\n",
    "    '''Build the subject database, with the subject key, name and prerequitites'''\n",
    "    laparams = LAParams(line_overlap=0.5,\n",
    "    char_margin=500, line_margin=2, word_margin=0.5,\n",
    "    boxes_flow=0.5, detect_vertical=False, all_texts=False)\n",
    "    text = extract_text(matriz_pdf,laparams=laparams)\n",
    "\n",
    "    #This first expression fixes the side effect of the pdf reader putting prerequisites in new lines\n",
    "    #substitute the newline for a comma just between prerequisites\n",
    "    exp = r\",\\n[A-Z]{3}\\d{5}\"\n",
    "    def repl(m):\n",
    "        #print(m.group(0)[2:])\n",
    "        return(\",\"+m.group(0)[2:])\n",
    "\n",
    "    fixed_prerequisites=re.sub(exp,repl,text)\n",
    "    \n",
    "    exp2 = r\"[A-Z]{3}\\d{5}.*[A-Z]{3}\\d{5}\"\n",
    "    subjects_prerequisites = re.findall(exp2,fixed_prerequisites,re.M) \n",
    "    subjects_prerequisites\n",
    "\n",
    "    #~improove this repetition of .split()~\n",
    "    #prerequisites = {x.split()[0]:x.split()[-1] for x in subjects_prerequisites}\n",
    "    prerequisites = {x[0]:x[-1].split(\",\") for x in [y.split() for y in subjects_prerequisites]}\n",
    "    subject_names = {x[0]:x[-2] for x in [y.split() for y in subjects_prerequisites]}\n",
    "\n",
    "    return prerequisites,subject_names\n",
    "#Prerequisite_Dict(\"2014-MatrizCurricularComputacao.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Subjects_Demand(prerequisites,approved_subjects):\n",
    "    '''Finds the subjects the student have the possibility to attend, by not being approved and having the prerequisites'''\n",
    "    def Is_sublist(sublist,list):\n",
    "        return set(sublist) <= set(list)\n",
    "\n",
    "    subjects_demand = [subject for subject in prerequisites.keys() if \n",
    "    (subject not in approved_subjects and Is_sublist(prerequisites[subject],approved_subjects))] \n",
    "    return subjects_demand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF01113 ParadigmasdeLinguagensdeProgramação\n",
      "MAT01201 EstatísticaEProbabilidades\n",
      "INF01202 EstruturadeDadosII\n",
      "INF01204 SistemaOperacional\n",
      "INF01203 ProgramaçãoOrientadaaObjetos\n",
      "INF01201 AnáliseeProjetodeSistemas\n",
      "INF01206 BancodeDadosII\n",
      "INF01211 PesquisaOperacional\n"
     ]
    }
   ],
   "source": [
    "#Complete for one student\n",
    "prerequisites,subject_names = Subject_Dict(\"2014-MatrizCurricularComputacao.pdf\")\n",
    "approved_subjects = Approved_Subjects(\"extrato_escolar.pdf\")\n",
    "subjects_demand = Subjects_Demand(prerequisites,approved_subjects)\n",
    "\n",
    "for subject_key in subjects_demand:\n",
    "    print(subject_key, subject_names[subject_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Putting it all toghether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Aggregate_Demand(extratos,prerequisites):\n",
    "    for extrato in extratos:\n",
    "        approved_subjects = Approved_Subjects(extrato)\n",
    "        subjects_demand = Subjects_Demand(prerequisites,approved_subjects)\n",
    "        for subject in subjects_demand:\n",
    "            if subject not in aggregate_demand:\n",
    "                aggregate_demand[subject] = 1 \n",
    "            else:\n",
    "                aggregate_demand[subject] += 1\n",
    "    return aggregate_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ext_-_JVFD.pdf', 'extrato_escolar.pdf', 'extrato_ze.pdf']"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Read_Files_in_Folder():\n",
    "    files = os.listdir()\n",
    "    return files\n",
    "\n",
    "def Extratos(files):     \n",
    "    extratos = [file for file in files if file[-3:] == \"pdf\" and \"Matriz\" not in file]\n",
    "    #extratos = [\"extrato_escolar.pdf\",\"Ext_-_JVFD.pdf\",\"extrato_ze.pdf\"]\n",
    "    return extratos \n",
    "files = Read_Files_in_Folder()\n",
    "Extratos(files)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 INF01113 ParadigmasdeLinguagensdeProgramação\n",
      "3 MAT01201 EstatísticaEProbabilidades\n",
      "3 INF01202 EstruturadeDadosII\n",
      "3 INF01204 SistemaOperacional\n",
      "3 INF01203 ProgramaçãoOrientadaaObjetos\n",
      "3 INF01201 AnáliseeProjetodeSistemas\n",
      "3 INF01206 BancodeDadosII\n",
      "3 INF01211 PesquisaOperacional\n",
      "1 FIS01103 FísicaGeralII\n"
     ]
    }
   ],
   "source": [
    "extratos = Extratos(files)\n",
    "\n",
    "prerequisites,subject_names = Subject_Dict(\"2014-MatrizCurricularComputacao.pdf\")\n",
    "aggregate_demand = {}\n",
    "aggregate_demand = Aggregate_Demand(extratos,prerequisites)\n",
    "\n",
    "for subject_key in aggregate_demand.keys():\n",
    "    print(aggregate_demand[subject_key],subject_key,subject_names[subject_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studied the possibility of pickle for permanence, but json  seems more adequate for the project due to the human readable, small size of content and security in reading.\n",
    "import pickle\n",
    "dictionary_data = {\"a\": 1, \"b\": 2}\n",
    "\n",
    "a_file = open(\"data.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(dictionary_data, a_file)\n",
    "\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"data.pkl\", \"rb\")\n",
    "\n",
    "output = pickle.load(a_file)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##json workflow developing \n",
    "def Save_Dict_to_JSON(dict,json_file):\n",
    "    with open(json_file,'w') as f:\n",
    "        json.dump(dict,f)\n",
    "\n",
    "def Read_JSON_to_Dict(json_file):\n",
    "    with open(json_file,'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "Save_Dict_to_JSON(dictionary_data,\"test.json\")\n",
    "Read_JSON_to_Dict(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Expand the extraction system to supply more information considering a future more complete dashboard\n",
    "#      - Data such as: grades, situation of each subject, year of students registration, student's name?...\n",
    "#      - In this case, would it be better to use pandas? Because I tried to keep minimal dependences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'subjects_dict.json' sucssesfully loaded.\n",
      "1 Extracts processed.\n",
      "2 Extracts processed.\n",
      "3 Extracts processed.\n",
      "4 Extracts processed.\n",
      "Aggregate Demand sucssesfully calculated.\n",
      "Results preview:\n",
      "['Sigla', 'Diciplina', 'Demanda']\n",
      "['INF01204', 'SistemaOperacional', 1]\n",
      "['INF01201', 'AnáliseeProjetodeSistemas', 4]\n",
      "['MAT01107', 'ProcessosEstocásticos', 3]\n",
      "['INF01116', 'BancodeDadosI', 4]\n",
      "['INF01117', 'LinguagensFormaiseTeoriadaComputação', 4]\n",
      "['INF01205', 'InteligênciaArtiﬁcial', 4]\n",
      "['PRO01540', 'Empreendedorismo', 3]\n",
      "['FIS01103', 'FísicaGeralII', 2]\n",
      "['INF01115', 'RedesdeComputadores', 3]\n",
      "['MAT01105', 'CálculoDiferencialeIntegralIII', 1]\n",
      "['MAT01106', 'MétodoMatemático', 1]\n",
      "'../Results/RESULTS_aggregate_demand.csv' sucessfuly written!\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.layout import LAParams\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "log = []\n",
    "\n",
    "\n",
    "def Read_Files_in_Folder():\n",
    "    files = os.listdir()\n",
    "    return files\n",
    "\n",
    "def Read_JSON_to_Dict(json_file):\n",
    "    try:\n",
    "        with open(json_file,'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return -1  \n",
    "\n",
    "def Save_Dict_to_JSON(dict,json_file):\n",
    "    with open(json_file,'w') as f:\n",
    "        json.dump(dict,f)\n",
    "\n",
    "def Save_CSV(table,csv_file_name):\n",
    "    with open(csv_file_name,'w') as csvfile:\n",
    "        writer = csv.writer(csvfile) \n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "    print(\"'\"+csv_file_name+\"'\",\"sucessfuly written!\")\n",
    "#-------------------------------------------------\n",
    "\n",
    "#dicipline_equivalence = {\"PRO01121\":\"MAT01201\"}\n",
    "dicipline_equivalence = Read_JSON_to_Dict(\"../Config/dicipline_equivalences.json\")\n",
    "\n",
    "#------------------------------------------------\n",
    "def Correction(target,correction_rules):\n",
    "    '''Replaces the target substrings in the text according to the correction_rules'''\n",
    "    fixed_target = target\n",
    "    for phrase,fixed_phrase in correction_rules.items():\n",
    "        fixed_target = fixed_target.replace(phrase,fixed_phrase)\n",
    "    return fixed_target \n",
    "    \n",
    "def Subject_Dict_prerequisites_names(files):\n",
    "    '''Return a subjects_dict with the subject keys, names and prerequisites'''\n",
    "    def _Build_prerequisites_names_Dict(matriz_pdf):\n",
    "        '''Build the subject database, with the subject key, name and prerequitites'''\n",
    "        laparams = LAParams(line_overlap=0.5,\n",
    "        char_margin=500, line_margin=2, word_margin=0.5,\n",
    "        boxes_flow=0.5, detect_vertical=False, all_texts=False)\n",
    "        matriz_raw = extract_text(matriz_pdf,laparams=laparams)\n",
    "\n",
    "        #TODO: should we make a global \"correction_rules\"?\n",
    "        matriz_correction_rules = {\"INF01106 BancodeDadosI\":\"INF01116 BancodeDadosI\",\n",
    "                \"BancodeDadosII INF01106\":\"BancodeDadosII INF01116\"}\n",
    "        matriz = Correction(matriz_raw,matriz_correction_rules)\n",
    "        log.append(matriz)\n",
    "\n",
    "        #This first expression fixes the side effect of the pdf reader putting prerequisites in new lines\n",
    "        #substitute the newline for a comma just between prerequisites\n",
    "        exp = r\",\\n[A-Z]{3}\\d{5}\"\n",
    "        def repl(m):\n",
    "            #print(m.group(0)[2:])\n",
    "            return(\",\"+m.group(0)[2:])\n",
    "\n",
    "        fixed_prerequisites=re.sub(exp,repl,matriz)\n",
    "        \n",
    "        exp2 = r\"[A-Z]{3}\\d{5}.*[A-Z]{3}\\d{5}\"\n",
    "        subjects_prerequisites = re.findall(exp2,fixed_prerequisites,re.M)\n",
    "        log.append(subjects_prerequisites) \n",
    "\n",
    "        #~improove this repetition of .split()~\n",
    "        #prerequisites = {x.split()[0]:x.split()[-1] for x in subjects_prerequisites}\n",
    "        prerequisites = {x[0]:x[-1].split(\",\") for x in [y.split() for y in subjects_prerequisites]}\n",
    "        subject_names = {x[0]:x[-2] for x in [y.split() for y in subjects_prerequisites]}\n",
    "        subject_dict = {\"names\":subject_names,\"prerequisites\":prerequisites}\n",
    "\n",
    "        Save_Dict_to_JSON(subject_dict,\"../Config/subjects_dict.json\")\n",
    "        print(\"'subjects_dict.json' sucssesfully built and loaded.\")\n",
    "        return subject_dict \n",
    "\n",
    "    dict = Read_JSON_to_Dict(\"../Config/subjects_dict.json\")\n",
    "    if dict == -1:\n",
    "        #TODO: improve the safety with a try catch \n",
    "        matriz_pdf = os.listdir(\"../Matriz_Curricular\")[-1]\n",
    "        if matriz_pdf == []:\n",
    "            #return \"Error! Neither 'subjects_dict.json' nor MatrizCurricular were not found.\"\n",
    "            return -1\n",
    "        else:\n",
    "            print(\"'subjects_dict.json' not found. Lets build it!\")\n",
    "            return _Build_prerequisites_names_Dict(\"../Matriz_Curricular/\"+matriz_pdf)\n",
    "    else:\n",
    "        print(\"'subjects_dict.json' sucssesfully loaded.\")\n",
    "        return dict \n",
    "\n",
    "#def Extratos(files):\n",
    "#    '''Return a list of all the students extracts in the folder.\n",
    "#        Determined by not being the \"MatrizCurricular.pdf\" '''\n",
    "#    pdfs = [file for file in files if file[-3:] == \"pdf\"]\n",
    "#    #extratos = [\"extrato_escolar.pdf\",\"Ext_-_JVFD.pdf\",\"extrato_ze.pdf\"]\n",
    "#    extratos = [pdf for pdf in pdfs if \"Matriz\" not in pdf]\n",
    "#    return extratos \n",
    "def Extratos():\n",
    "    '''Return the filenames of students extract inside the folder \"Extratos_Academicos\"'''\n",
    "    return [\"../Extratos_Academicos/\"+extrato for extrato in os.listdir(\"../Extratos_Academicos\")]\n",
    "\n",
    "def Aggregate_Demand(extratos,prerequisites):\n",
    "    '''Reads each students extract to find the completed subjects and their subsequent demands'''\n",
    "    #TODO improove this commet\n",
    "    def _Approved_Subjects(student_extract_pdf):\n",
    "        '''Return approved subject keys from the student's academic extract'''\n",
    "        #Ideal layout parameters:\n",
    "        laparams = LAParams(line_overlap=0.5,\n",
    "            char_margin=95.0, line_margin=2, word_margin=0.5,\n",
    "            boxes_flow=0.5, detect_vertical=False, all_texts=False)\n",
    "        #Reading pdf to string\n",
    "        extract_raw = extract_text(student_extract_pdf,laparams=laparams)\n",
    "        extract = Correction(extract_raw,dicipline_equivalence)\n",
    "\n",
    "\n",
    "        #Filter from \"extrato\" all the lines begining with a subject key\n",
    "        attended_subjects = re.findall(r\"[A-Z]{3}\\d{5}.*\",extract) #print(attended_subjects)\n",
    "        #Filter the approved subjects and the subjects exempt through the special pandemic period (AAREs) \n",
    "        approved_subjects = [att_sub.split(\" \",1)[0] for att_sub in attended_subjects if (\"APR\" in att_sub or len(att_sub) == 12)]\n",
    "        return approved_subjects \n",
    "\n",
    "    def _Subjects_Demand(prerequisites,approved_subjects):\n",
    "        '''Finds subjects the student have the possibility to attend.\n",
    "        That is, unnatended subjects that the student already has the prerequisites'''\n",
    "        def Is_sublist(sublist,list):\n",
    "            return set(sublist) <= set(list)\n",
    "\n",
    "        subjects_demand = [subject for subject in prerequisites.keys() if \n",
    "        (subject not in approved_subjects and Is_sublist(prerequisites[subject],approved_subjects))] \n",
    "        return subjects_demand\n",
    "\n",
    "    aggregate_demand = {}\n",
    "    i = 0 \n",
    "    for extrato in extratos:\n",
    "        approved_subjects = _Approved_Subjects(extrato)\n",
    "        subjects_demand = _Subjects_Demand(prerequisites,approved_subjects)\n",
    "        for subject in subjects_demand:\n",
    "            if subject not in aggregate_demand:\n",
    "                aggregate_demand[subject] = 1 \n",
    "            else:\n",
    "                aggregate_demand[subject] += 1\n",
    "        print(i+1,\"Extracts processed.\")\n",
    "        i+=1\n",
    "    print(\"Aggregate Demand sucssesfully calculated.\\nResults preview:\")\n",
    "    return aggregate_demand\n",
    "\n",
    "def Final_Demand(aggregate_demand,subject_dict):\n",
    "    '''Consolidates the aggregate_demand into a structured result.'''\n",
    "    final_demand = [[\"Sigla\",\"Diciplina\",\"Demanda\"]]\n",
    "    print(final_demand[-1])\n",
    "    for subject,demand in aggregate_demand.items():\n",
    "        final_demand.append([subject,subject_dict[\"names\"][subject],demand])\n",
    "        print(final_demand[-1])\n",
    "    \n",
    "        \n",
    "    Save_CSV(final_demand,\"../Results/RESULTS_aggregate_demand.csv\")\n",
    "\n",
    "def main():\n",
    "    files = Read_Files_in_Folder()\n",
    "    subject_dict = Subject_Dict_prerequisites_names(files)\n",
    "    if subject_dict == -1:\n",
    "        return \"Error! Neither 'subjects_dict.json' nor MatrizCurricular were found in the current folder:\\n\"+os.getcwd()\n",
    "    else:\n",
    "        extratos = Extratos()\n",
    "        aggregate_demand = Aggregate_Demand(extratos,subject_dict[\"prerequisites\"])\n",
    "        Final_Demand(aggregate_demand,subject_dict)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##json workflow developing \n",
    "def Save_Dict_to_JSON(dict,json_file):\n",
    "    with open(json_file,'w') as f:\n",
    "        json.dump(dict,f)\n",
    "\n",
    "def Read_JSON_to_Dict(json_file):\n",
    "    try:\n",
    "        with open(json_file,'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return -1  \n",
    "\n",
    "\n",
    "Save_Dict_to_JSON(dictionary_data,\"test.json\")\n",
    "Read_JSON_to_Dict(\"test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drafting a function to save the results in CSV\n",
    "import csv\n",
    "def Save_CSV(table,csv_file_name):\n",
    "    with open(csv_file_name,'w') as csvfile:\n",
    "        writer = csv.writer(csvfile) \n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "    print(csv_file_name,\"sucessfuly written!\")\n",
    "\n",
    "final_demand = [['Sigla', 'Diciplina', 'Demanda'], ['INF01113', 'ParadigmasdeLinguagensdeProgramação', 3], ['MAT01201', 'EstatísticaEProbabilidades', 3], ['INF01202', 'EstruturadeDadosII', 3], ['INF01204', 'SistemaOperacional', 3], ['INF01203', 'ProgramaçãoOrientadaaObjetos', 3], ['INF01201', 'AnáliseeProjetodeSistemas', 3], ['INF01206', 'BancodeDadosII', 3], ['INF01211', 'PesquisaOperacional', 3], ['FIS01103', 'FísicaGeralII', 1]]\n",
    "Save_CSV(final_demand,\"teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 56, 3, 3, 32, 3, 56, 4, 5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drafting a implementation to easily stablish subjects equivalence\n",
    "# Maybe the same function can fix the MatrizCurricular error with INF01106 \n",
    "l = [1,1,3,3,32,3,1,4,5]\n",
    "dict = {1:56}\n",
    "a = []\n",
    "for key in l:\n",
    "    if key in dict:\n",
    "        a.append(dict[key])\n",
    "    else:\n",
    "        a.append(key)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF01106 BancodeDadosI INF01116 BancodeDadosI\n",
      "BancodeDadosII INF01106 BancodeDadosII INF01116\n",
      "DisciplinasObrigatóriasporSemestre AAAAAAAAAA\n"
     ]
    }
   ],
   "source": [
    "# log[0].split(\"INF01115\")[1]\n",
    "# \"INF01106 BancodeDadosI\" -> \"INF01116 BancodeDadosI\"\n",
    "# \"BancodeDadosII INF01106\" -> \"BancodeDadosII INF01116\"\n",
    "\n",
    "correction_rules = {\"INF01106 BancodeDadosI\":\"INF01116 BancodeDadosI\",\n",
    "                \"BancodeDadosII INF01106\":\"BancodeDadosII INF01116\",\n",
    "                \"DisciplinasObrigatóriasporSemestre\":\"AAAAAAAAAA\"}\n",
    "\n",
    "def Correction(target,correction_rules):\n",
    "    fixed_target = target\n",
    "    for phrase,fixed_phrase in correction_rules.items():\n",
    "        print(phrase,fixed_phrase)\n",
    "        fixed_target = fixed_target.replace(phrase,fixed_phrase)\n",
    "    return fixed_target \n",
    "\n",
    "fixed = Correction(log[0],correction_rules)\n",
    "\n",
    "#re.findall(r\"INF01116\",fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2014-MatrizCurricularComputacao.pdf']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../Matriz_Curricular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.vscode',\n",
       " '.gitignore',\n",
       " '.git',\n",
       " 'readme.md',\n",
       " 'Aggregate_Demand.py',\n",
       " 'Extratos_Antigos',\n",
       " 'Results',\n",
       " 'Config',\n",
       " 'Extratos_Academicos',\n",
       " 'Matriz_Curricular',\n",
       " 'Development']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../Ma\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
